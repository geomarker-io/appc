---
title: "CV Model Performance"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

# load development version if developing (instead of currently installed version)
if (file.exists("./inst") || basename(getwd()) == "inst") {
  devtools::load_all()
} else {
  library(appc)
}
library(grf)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)

the_theme <- 
  ggplot2::theme_light(base_size = 11) +
  ggplot2::theme(
    panel.background = ggplot2::element_rect(fill = "white", colour = NA),
    panel.border = ggplot2::element_rect(fill = NA, colour = "grey20"),
    panel.grid.major = ggplot2::element_line(colour = "grey92"),
    panel.grid.minor = ggplot2::element_blank(),
    strip.background = ggplot2::element_rect(fill = "grey92", colour = "grey20"),
    strip.text = ggplot2::element_text(color = "grey20"), legend.key = ggplot2::element_rect(fill = "white", colour = NA),
    complete = TRUE
  )
```

```{r load_model_and_predictions}
grf <- appc:::load_rf_pm_model(model_version = packageVersion('appc')$major)

train_file <- fs::path(tools::R_user_dir("appc", "data"), glue::glue("training_data_v{packageVersion('appc')$major}.rds"))
if(!file.exists(train_file)) {
  maj <- packageVersion("appc")$major
  download.file(glue::glue("https://github.com/geomarker-io/appc/releases/download/rf_pm_v{maj}/training_data_v{maj}.rds"), train_file)
}
d_train <- readRDS(train_file)
```

## Training Data

```{r pm_edges}
pm_main <- quantile(d_train$conc, c(0.025, 0.975))
```

Training data consisted of `r prettyNum(nrow(d_train), ",")` daily average PM$_{2.5}$ concentrations from `r prettyNum(n_distinct(d_train$s2), ",")` EPA AQS monitors on `r prettyNum(n_distinct(d_train$date), ",")` days between `r min(d_train$date)` and `r max(d_train$date)`.

Overall, the median measured PM$_{2.5}$ was `r median(d_train$conc)` $\mu g/ m^3$
and 99.5% of all measurements were between `r pm_main[1]` and `r pm_main[2]` $\mu g/ m^3$:

```{r pm25_histogram}
d_train|>
  ggplot(aes(conc)) +
  geom_histogram(binwidth = 1) +
  scale_x_continuous(limits = pm_main) +
  the_theme +
  xlab(expression(Measured ~ paste(PM[2.5], " (", mu, "g/", m^{3}, ") "))) +
  ylab("Number of Measurements")
```

## Model Training

The EPA AQS monitor concentrations were used to train a generalized regression forest with `r grf[["_num_trees"]]` trees, a subsample fraction of `r grf$tunable.params$sample.fraction`, a minimum node size of `r grf$tunable.params$min.node.size`, and an $m_{try}$ value of `r grf$tunable.params$mtry`.

Model predictors listed in the table below are ordered according to their importance.  Here, the variable importance is calculated as an exponentially-weighted sum of how many times each feature was selected within the first 6 splits of each tree in the forest.

```{r "variable importance"}
pred_names <- names(grf$X.orig)

tibble(importance = round(variable_importance(grf, decay.exponent = 2, max.depth = 6), 2),
       variable = pred_names) |>
  nest_by(importance) |>
  arrange(desc(importance)) |>
  mutate(predictor = list(data$variable)) |>
  select(-data) |>
  mutate(predictor = list(paste(predictor, collapse = ", "))) |>
  tidyr::unnest(cols = c(predictor)) |>
  knitr::kable()
```

## Leave One Location Out (LOLO) Cross Validated Model Performance

```{r "estimate variance of predictions"}
d <-
  grf |>
  predict(estimate.variance = TRUE) |>
  tibble::as_tibble() |>
  transmute(
    pred = signif(predictions, 2),
    se = signif(sqrt(variance.estimates), 2),
    conc = grf$Y.orig) |>
  bind_cols(select(d_train, s2, date))
d <- d |>
  mutate(lci = pred - se * qnorm(0.025, lower.tail = FALSE),
         uci = pred + se * qnorm(0.025, lower.tail = FALSE),
         ci_covered = conc < uci & conc > lci)
```

```{r "add temporal components"}
d$year <- as.numeric(format(d$date, "%Y"))
d$month <- as.numeric(format(d$date, "%m"))
d$week <- as.numeric(format(d$date, "%U"))
```

Leave-one-location-out (LOLO) accuracy is calculated by using out of bag predictions from the trained random forest with resample clustering by the location. 
Accuracy is characterized using median absolute error (`mae`) and the Spearman's correlation coefficient (`rho`). 
Accuracy metrics are calculated for each left out location and then summarized using the median accuracy statistic across all locations. 
This most closely captures the performance in a real-world scenario where we are trying to predict air pollution between 2017 and 2025 in a place where it was not measured.

Each AQS monitor has a different number of measurements depending on its measurement frequency and when it was deployed. 
To calculate LOLO model performance, we exclude any station or station-time grouping that has 4 or less observations. 
In the tables below, `median_n` represents the median number of observations used in each station grouping to calculate the overall median accuracy metrics. 
`ci_coverage` is the percentage of the time that the 95% CI interval of the predicted concentration contained the measured concentration.

### Daily

```{r "daily accuracy"}
d |>
  nest_by(s2) |>
  mutate(n_obs = c(nrow(data))) |>
  filter(n_obs > 4) |>
  mutate(mae = c(median(abs(data$conc - data$pred))),
         rho = c(cor.test(data$conc, data$pred, method = "spearman", exact = FALSE)$estimate),
         ci_coverage = c(sum(data$ci_covered) / length(data$ci_covered))) |>
  ungroup() |>
  summarize(mae = median(mae),
            rho = median(rho),
            ci_coverage = scales::percent(median(ci_coverage)),
            median_n = median(n_obs)) |>
  knitr::kable(digits = 2)
```

#### Actual PM2.5 Concentrations vs LOLO Daily Predictions

```{r "daily pred vs actual plot"}
d |>
  ggplot(aes(conc, pred)) +
  stat_bin_hex(binwidth = c(0.05, 0.05)) +
  viridis::scale_fill_viridis(option = "C", trans = "log10", name = "Number \nof points") +
  geom_abline(slope = 1, intercept = 0, lty = 2, alpha = 0.8, color = "darkgrey") +
  scale_x_log10(limits = c(1, 300)) + scale_y_log10(limits = c(1, 300)) +
  xlab(expression(Observed ~ paste(PM[2.5], " (", mu, "g/", m^{3}, ") "))) +
  ylab(expression(CV ~ Predicted ~ paste(PM[2.5], " (", mu, "g/", m^{3}, ") "))) +
  the_theme +
  theme(legend.position = c(0.85, 0.2)) +
  coord_fixed()
```

#### Daily Prediction Accuracies per Calendar Year

```{r "daily accuracies per year"}
d |>
  nest_by(s2, year) |>
  mutate(n_obs = c(nrow(data))) |>
  filter(n_obs > 4) |>
  mutate(mae = c(median(abs(data$conc - data$pred))),
         rho = c(cor.test(data$conc, data$pred, method = "spearman", exact = FALSE)$estimate),
         ci_coverage = c(sum(data$ci_covered) / length(data$ci_covered))) |>
  group_by(year) |>
  summarize(mae = median(mae),
            rho = median(rho),
            ci_coverage = scales::percent(median(ci_coverage)),
            median_n = median(n_obs)) |>
  knitr::kable(digits = 2)
```

### Monthly

Exclude stations with 4 or less total monthly observations.

```{r "monthly accuracies"}
d |>
  group_by(s2, year, month) |>
  summarize(pred = mean(pred),
            conc = mean(conc),
            se = mean(sqrt(se^2))) |>
  mutate(lci = pred - se * qnorm(0.025, lower.tail = FALSE),
         uci = pred + se * qnorm(0.025, lower.tail = FALSE),
         ci_covered = conc < uci & conc > lci) |>
  ungroup() |>
  nest_by(s2) |>
  mutate(n_obs = c(nrow(data))) |>
  filter(n_obs > 4) |>
  mutate(mae = c(median(abs(data$conc - data$pred))),
         rho = c(cor.test(data$conc, data$pred, method = "spearman", exact = FALSE)$estimate),
         ci_coverage = c(sum(data$ci_covered) / length(data$ci_covered))) |>
  ungroup() |>
  summarize(mae = median(mae),
            rho = median(rho),
            ci_coverage = scales::percent(median(ci_coverage)),
            median_n = median(n_obs)) |>
  knitr::kable(digits = 2)
```

### Annual

Exclude stations with 4 or less total annual observations.

```{r "yearly accuracies"}
d |>
  group_by(s2, year) |>
  summarize(pred = mean(pred),
            conc = mean(conc),
            se = mean(sqrt(se^2))) |>
  mutate(lci = pred - se * qnorm(0.025, lower.tail = FALSE),
         uci = pred + se * qnorm(0.025, lower.tail = FALSE),
         ci_covered = conc < uci & conc > lci) |>
  ungroup() |>
  nest_by(s2) |>
  mutate(n_obs = c(nrow(data))) |>
  filter(n_obs > 4) |>
  mutate(mae = c(median(abs(data$conc - data$pred))),
         rho = c(cor.test(data$conc, data$pred, method = "spearman", exact = FALSE)$estimate),
         ci_coverage = c(sum(data$ci_covered) / length(data$ci_covered))) |>
  ungroup() |>
  summarize(mae = median(mae),
            rho = median(rho),
            ci_coverage = scales::percent(median(ci_coverage)),
            median_n = median(n_obs)) |>
  knitr::kable(digits = 2)
```

### Median LOLO Accuracy Per Spatial Aggregation Period

Station-specific estimates of crossvalidated MAE and Rho were spatially aggregated to level 5 s2 cells and summarized. The visualized result is a rough approximation of how model performance may differ in different parts of the country:

```{r "spatial variation in accuracies"}
library(s2)

the_map_theme <-
  the_theme +
  ggplot2::theme(
    axis.ticks = ggplot2::element_blank(), 
    axis.text = ggplot2::element_blank(),
    axis.title = ggplot2::element_blank(), 
    rect = ggplot2::element_blank(),
    line = ggplot2::element_blank(), 
    panel.grid = ggplot2::element_blank(),
    plot.margin = ggplot2::margin(1, 1, 1, 1, "cm"),
    legend.key.height = ggplot2::unit(1, "cm"),
    legend.key.width = ggplot2::unit(0.3, "cm")
  )

d |>
  mutate(s2_ = s2_cell_parent(s2, 5)) |>
  nest_by(s2, s2_) |>
  mutate(n_obs = c(nrow(data))) |>
  filter(n_obs > 4) |>
  mutate(mae = c(median(abs(data$conc - data$pred))),
         rho = c(cor.test(data$conc, data$pred, method = "spearman", exact = FALSE)$estimate),
         ci_coverage = c(sum(data$ci_covered) / length(data$ci_covered))) |>
  group_by(s2_) |>
  summarize(mae = median(mae),
            s2_ = unique(s2_)) |>
  mutate(geometry = s2_cell_polygon(s2_)) |>  
  sf::st_as_sf() |>
  ggplot() +
  geom_sf(aes(fill = mae), size = 0) +
  coord_sf(crs = 5072) +
  the_map_theme +
  scale_fill_viridis_c() +
  theme(legend.position = c(0.25, 0.1),
        legend.direction = "horizontal",
        legend.title = element_text(size = 11, family = "sans"),
        legend.text = element_text(size = 11),
        legend.box = "hortizontal",
        legend.key.height = unit(4, "mm"),
        legend.key.width = unit(9, "mm"),
        strip.text.x = element_text(size = 11, face = "bold", vjust = 1),
        strip.text.y = element_text(size = 11, face = "bold")) +
  labs(fill = expression(paste(MAE~(ug/m^3)))) +
  guides(fill = guide_colorbar(title.position = "top", title.hjust = 0.5))
```
